# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

category: conference
tags:
    - web
speaker:
    name: 'Siraj Raval'
    twitter: sirajraval
    matches: [sirajraval]
title: 'Solving the Basic Game of Pong'
language: English
recordingDate: 1512781406
description: "Building an AI to beat pong using just the pixels of the screen as input with no hard-coded rules? Yes, its possible. We'll solve this using an approach called \"Policy Gradients\" which is even more popular than Q-learning. I'll show you how its done using a mix of animations, code, and theory. Let's beat pong!\n\nCode (and challenge) for this week:\nhttps://github.com/llSourcell/policy_gradients_pong\n\nAlex's Winning code:\nhttps://github.com/msoedov/q-learner\n\nAditya's Runner up code:\nhttps://github.com/avp1598/q_learning\n\nPlease Subscribe! And like. And comment. That's what keeps me going.\n\nWant more inspiration & education? Connect with me:\nTwitter: https://twitter.com/sirajraval\n\nFacebook: https://www.facebook.com/sirajology\n\nMore learning resources:\nhttp://karpathy.github.io/2016/05/31/rl/\nhttps://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-2-ded33892c724\nhttp://minpy.readthedocs.io/en/latest/tutorial/rl_policy_gradient_tutorial/rl_policy_gradient.html\nhttp://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html\nhttp://kvfrans.com/simple-algoritms-for-solving-cartpole/\nhttps://theneuralperspective.com/2016/11/25/reinforcement-learning-rl-policy-gradients-i/\n\nJoin us in the Wizards Slack channel:\nhttp://wizards.herokuapp.com/\n\nAnd please support me on Patreon:\nhttps://www.patreon.com/user?u=3191693 Instagram: https://www.instagram.com/sirajraval/ Instagram: https://www.instagram.com/sirajraval/"
