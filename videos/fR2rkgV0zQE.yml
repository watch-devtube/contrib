# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

category: conference
tags:
    - ml
    - architecture
title: 'Distributed Deep Learning by Jim Dowling'
recordingDate: 1550058156
description: 'Methods that scale with computation are the future of AI", Richard Sutton, father of reinforcement learning. Large labelled training datasets were only one of the key pillars of the deep learning revolution, the widespread availability of GPU compute was the other. The next phase of deep learning is the widespread availability of distributed GPU compute. As data volumes increase, GPU clusters will be needed for the new distributed methods that already produce the state-of-the-art results for ImageNet and Cifar-10, such as neural architecture search. Auto-ml is also predicated on the availability of GPU clusters. But how do we integrate such technology into enterprises? In this talk, we will discuss the need for scale-out deep learning and the open-source Hops platfrom that supports GPUs as a resource and a secure multi-tenant environment that supports sandboxed environments for sensitive data.'
