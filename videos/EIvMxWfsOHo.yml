# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - ml
    - azure
title: 'Machine Learning Interpretability Toolkit'
language: English
recordingDate: 1571158802
description: "We will discuss a little about what it means to develop AI in a transparent way. We will introduce our interpretability toolkit which enables you to use different state-of-the-art interpretability methods to explain your models decisions. By using this toolkit during the training phase of the AI development cycle, you can use interpretability output of a model to verify hypotheses and build trust with stakeholders. You can also use the insights for debugging, validating model behavior, and to check for bias. You can also use this toolkit at inferencing time to explain the predictions of a deployed model to the end users.\n\nLearn More: \nLink to the doc: https://docs.microsoft.com/en-us/azure/machine-learning/service/machine-learning-interpretability-explainability?ocid=AID2463683&wt.mc_id=ai-c9-sejuare\nLink to the sample notebooks: https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/explain-model?ocid=AID2463683&wt.mc_id=ai-c9-sejuare\n \n02:12 – Responsible AI\n02:34 – Machine Learning Interpretability\n03:12 – Interpretability Use Cases\n05:20 - Different Interpretability Techniques\n06:45 - Demo\n\nDon't miss new episodes, subscribe to the AI Show: https://aka.ms/aishowsubscribe  \nCreate a Free account (Azure): https://aka.ms/aishow-seth-azurefree\nAI Blog: https://aka.ms/openaiblog\nFast ML: https://aka.ms/fastml   \nMIT News | AI: https://aka.ms/mitnews\nMedium | Francesca Lazzeri: https://medium.com/@francescalazzeri\nDeep Learning vs. Machine Learning: https://aka.ms/deeplearningmachinelearning\nFollow: https://twitter.com/sethjuarez\nFollow: https://twitter.com/ch9\nFollow: https://twitter.com/Azure\nFollow: https://twitter.com/msdev\n\n#microsoftai #machinelearning #interpretabilitytoolkit"
