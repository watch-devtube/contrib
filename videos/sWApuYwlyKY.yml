# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - bigdata
    - ml
    - tensorflow
    - performance
title: 'Democratizing Deep Learning with Tensorflow on Hops Hadoop'
language: English
recordingDate: 1520372958
description: "by Jim Dowling and Gautier Berthou\n\nAt: FOSDEM 2017\n\nAccording to Andrej Kaparthy, there are four main factors holding back AI:Compute, Data, Algorithms, and Infrastructure. In this talk, we will show howwe attack the Data and Infrastructure challenges for Deep Learning.Specifically, we will show how we integrated Tensorflow with the world's mostscalable and human-friendly distribution of Hadoop, Hops (www.hops.io). Hopsis a new European distribution of Hadoop with a distributed metadataarchitecture and 16X the performance of HDFS. Hops also includes a human-friendly UI, called Hopsworks, with support for the Apache Zeppelin Notebook.We will show how users can run tensorflow programs in Apache Zeppelin on hugedatasets in Hadoop. Moreover, we will show how Hopsworks makes discovering anddownloading huge datasets a piece of cake with peer-to-peer sharing ofdatasets between Hopsworks clusters. Within minutes, you can installHopsworks, discover curated important datasets and download them to train DeepNeural networks using Tensorflow. Hops is the first Hadoop distribution tosupport Tensorflow. Hops and Hopsworks are both Apache v2 licensed projectsand have been developed primarily at KTH Royal Institute of Technology andSICS Swedish ICT in Stockholm.\n\nAccording to Andrej Kaparthy, there are four main factors holding back AI:Compute, Data, Algorithms, and Infrastructure. In this talk, we will show howwe attack the Data and Infrastructure challenges for Deep Learning.Specifically, we will show how we integrated Tensorflow with the world's mostscalable and human-friendly distribution of Hadoop, Hops (www.hops.io). Hopsis a new European distribution of Hadoop with a distributed metadataarchitecture and 16X the performance of HDFS. Hops also includes a human-friendly UI, called Hopsworks, with support for the Apache Zeppelin Notebook.We will show how users can run tensorflow programs in Apache Zeppelin on hugedatasets in Hops Hadoop. Moreover, we will show how Hopsworks makesdiscovering and downloading huge datasets a piece of cake with custom peer-to-peer sharing of datasets between Hopsworks clusters. A new user can, withinminutes, install Hopsworks, discover curated important datasets and downloadthem to train Deep Neural networks using Tensorflow. Hops is the first Hadoopdistribution to support Tensorflow. Hopsworks itself is a self-service UI forHops Hadoop, that is based around projects, users, and dataset concepts. Userscollaborate in projects that contain datasets. Data owners can give usersaccess to process data (but not download it, copy it outside of the project,or cross-link it with data outside the project). Hopsworks, thus, providesstronger access control guarantees than are available in Hadoop, enablingsenstive data to securely reside on shared Hadoop clusters. Since April 2016,Hopsworks has provided Hadoop/Spark/Flink/Kafka-as-a-service to researchers inSweden from the Swedish ICT SICS Data Center at www.hops.site.\n\nHops and Hopsworks are both Apache v2 licensed projects and have beendeveloped primarily at KTH Royal Institute of Technology and SICS Swedish ICTin Stockholm.\n\n\nRoom: H.2213\nScheduled start: 2017-02-04 16:00:00"
